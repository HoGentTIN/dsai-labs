{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e39257b0",
   "metadata": {},
   "source": [
    "# Module 1. Samples\n",
    "\n",
    "## Getting Started with Jupyter Notebooks\n",
    "\n",
    "Jupyter Notebooks (or iPython Notebooks) are files with a mixture of Markdown and Python code. It's a very convenient format so we'll be using this quite a lot during this course!\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "To get started, it is not necessary to install software on your laptop. [Google Colab](https://colab.research.google.com/) is a free online iPython development environment, but it does require a Google account in order to use it. You can create a local clone of the Github repo with the lab assignments and upload the Notebook files you want to work with to Colab.\n",
    "\n",
    "Remark that the Google Colab environment has older versions installed of the Python libraries that we will be using throughout this course. Usually, that's not a problem, but sometimes you will run into errors, e.g. because some parameter in our Python code didn't exist yet in that version. The solution is to add a new code block at the beginning of your Notebook file with content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dfa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade matplotlib\n",
    "%pip install --upgrade scipy\n",
    "%pip install --upgrade statsmodels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45eea59b",
   "metadata": {},
   "source": [
    "You only have to do this in Notebooks where you encounter errors, and only for the libraries that cause these errors. The installation may take a while and you need to restart the Python runtime afterwards by clicking the button that appears.\n",
    "\n",
    "### Local environment\n",
    "\n",
    "If you prefer to have a local development environment, you need to install Python and Visual Studio Code with the necessary extensions for working with Python (e.g. Pylance, Jupyter, Jupyter Keymap, etc.) The first time you open a Notebook file, VSCode will offer you to install these extensions.\n",
    "\n",
    "To install Python and VSCode on Windows, we recommend using `winget`. First, check the latest version of Python on the [Python website](https://www.python.org/downloads/windows/). For example, at the time of writing, the latest version was 3.12.2. We'll need to specify the major and minor version (e.g. 3.12) when installing. Then, open a PowerShell or command prompt as Administrator and run:\n",
    "\n",
    "```console\n",
    "> winget install Microsoft.VisualStudioCode\n",
    "> winget install Python.Python.3.12\n",
    "```\n",
    "\n",
    "Remark that `winget upgrade --all` will install maintenance releases of Python, but it will not upgrade to a new major or minor version.\n",
    "\n",
    "Most Python scripts (or Jupyter Notebooks) for analyzing data use the same program libraries. The most important ones are:\n",
    "\n",
    "- `numpy` - multidimensional arrays, linear algebra, etc.\n",
    "- `scipy` - mathematics, science, engineering etc.\n",
    "- `pandas` - data-analysis and -manipulation\n",
    "- `matplotlib`, `seaborn` - data visualisation\n",
    "- `scikit-learn` - regression and machine learning\n",
    "\n",
    "You can install these using `pip`:\n",
    "\n",
    "```console\n",
    "> pip install matplotlib numpy pandas scipy seaborn scikit-learn statsmodels\n",
    "```\n",
    "\n",
    "Or, alteratively, by executing the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scipy\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf2e22",
   "metadata": {},
   "source": [
    "\n",
    "Since you usually need the same packages every time, it is best to put them at the top of every script or Notebook file you write. By convention, package names are often abbreviated in a consistent manner, e.g. `np` for `numpy`, `sns` for `seaborn`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import numpy as np                                  # \"Scientific computing\"\n",
    "import scipy.stats as stats                         # Statistical tests\n",
    "\n",
    "import pandas as pd                                 # Data Frame\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import matplotlib.pyplot as plt                     # Basic visualisation\n",
    "from statsmodels.graphics.mosaicplot import mosaic  # Mosaic diagram\n",
    "import seaborn as sns                               # Advanced data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddffd8",
   "metadata": {},
   "source": [
    "## Opening a Dataset, General Information\n",
    "\n",
    "You can read in a dataset from a variety of sources (Rajagopalan, 2021, p.158). You can specify a path to a file or even a URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Titanic dataset. (Rajagopalan, 2021, p. 106)\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/DataRepo2019/Data-files/master/titanic.csv')\n",
    "# Show the first few records of the Data Frame\n",
    "titanic.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e377baca",
   "metadata": {},
   "source": [
    "If you want to open a dataset that you stored on Google Drive (where Google Colab stores all your Notebooks), you can use the following code instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556425a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your Google Drive is accessible from within the notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load the dataset from your Google Drive (here, we stored it in a subfolder\n",
    "# called \"data\")\n",
    "titanic = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ef393a2",
   "metadata": {},
   "source": [
    "Let's take a look at the properties of the dataset we just loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3aad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many  rows does the DataFrame have?\n",
    "print(f\"Number of rows: {len(titanic)}\")\n",
    "# How many columns?\n",
    "print(f\"Number of columns: {len(titanic.columns)}\")\n",
    "# How many rows and columns, i.e. the shape\n",
    "print(f\"The shape of the Data Frame is: {titanic.shape}\")\n",
    "# General information about the DataFrame\n",
    "print(\"*\"*50)\n",
    "titanic.info()\n",
    "\n",
    "# Give the data type of each column.\n",
    "print(\"*\"*50)\n",
    "print(titanic.dtypes)\n",
    "\n",
    "# How many columns of each data type are there?\n",
    "#   Watch it! The book says to use get_dtype_counts(), but this method no longer exists\n",
    "print(\"*\"*50)\n",
    "print(titanic.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ec95c",
   "metadata": {},
   "source": [
    "## Indices\n",
    "\n",
    "The columns \"PassengerId\" is not an actual variabele, but contains a number to identify each observation. You can mark this column as an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.set_index(['PassengerId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3425b",
   "metadata": {},
   "source": [
    "## Qualitative variables\n",
    "\n",
    "Some of the variables, such as `Survived` and `Pclass`, are incorrectly considered to be quantitative. You can correct this by explicitly converting them to a **qualitative** (categorical) variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a192c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the variable Survived -> is considered to be quantitative\n",
    "print(titanic.Survived.describe())\n",
    "# Convert to a categorical variable\n",
    "titanic.Survived = titanic.Survived.astype('category')\n",
    "# Ask to describe once more -> now it is considered to be qualitative\n",
    "print(titanic.Survived.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96881d1",
   "metadata": {},
   "source": [
    "You can also mark variables as **ordinal**, that is, with an ordering. We will do this as an example with the variable \"Embarked\" and order the ports in the order of departure. The Titanic departed at SouthHampton, and then picked up passengers first at Cherbourg and then at Queenstown.\n",
    "\n",
    "For cases like this, define your own datatype specifying the order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2223ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.Embarked.unique())\n",
    "\n",
    "embarked_type = CategoricalDtype(categories=['S', 'C', 'Q'], ordered=True)\n",
    "titanic.Embarked = titanic.Embarked.astype(embarked_type)\n",
    "titanic.Embarked.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1808f375",
   "metadata": {},
   "source": [
    "This order will then always be respected, e.g. in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4af2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic, x='Embarked');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccfdf9",
   "metadata": {},
   "source": [
    "## Selecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22945701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all observations for a single variable (i.e. a DataFrame column)\n",
    "titanic.Age\n",
    "# This also works (and is prefarable as it will also work when the column name has a space in it):\n",
    "# titanic['Age']\n",
    "# This also works, but isn't very nice\n",
    "# titanic.loc[:, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select adjacent columns\n",
    "titanic.iloc[:, 2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267f2d9",
   "metadata": {},
   "source": [
    "You can also select multiple columns based on their names.\n",
    "This is often clearer than selecting based on position and the columns must \n",
    "not be adjacent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3071015",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[['Name', 'Age', 'Cabin']] # Note: two sets of square brackets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation with row number 5 (counting from zero)\n",
    "print(titanic.iloc[5])\n",
    "\n",
    "# The first 4 observations\n",
    "titanic.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select observations where the value of Age is less than 18\n",
    "titanic[titanic.Age < 18]  \n",
    "\n",
    "# The same, but only keep the column 'Embarked'\n",
    "titanic[titanic.Age < 18].Embarked\n",
    "\n",
    "# The same, but keep columns 'Age' and 'Embarked'\n",
    "titanic[titanic['Age'] < 18][['Age', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f74c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all boys younger than 10\n",
    "titanic.query(\"(Sex=='male') and (Age < 18)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b425a",
   "metadata": {},
   "source": [
    "## Dropping Data and Working with Missing Data\n",
    "\n",
    "Pandas tries to make working with missing data as easy as possible. E.g., all of the descriptive statistics on pandas objects exclude missing data by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3c6e1",
   "metadata": {},
   "source": [
    "Let's starting by reading the titanic data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb502f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('https://raw.githubusercontent.com/DataRepo2019/Data-files/master/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc827a",
   "metadata": {},
   "source": [
    "The `PassengerId` column is identical to the index hence it doesn't provide any additional useful information. Let's drop this column (rather than setting it as the index as before). This can by done using `drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(\"PassengerId\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dd910",
   "metadata": {},
   "source": [
    "Notice that we actually didn't change the `titanic` `DataFrame`.  We can either assign the result of `drop` to a (new) `DataFrame`\n",
    "or we can use `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e010cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(3) # PassengerId is still here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop(\"PassengerId\", axis=\"columns\")\n",
    "titanic.head(3) # PassengerId is now gone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d91b4b",
   "metadata": {},
   "source": [
    "From the output of the `info` method we can infer that certain columns contain many missing values, e.g. `Cabin` only contains 204 non-missing values. \n",
    "For the purposes of illustration, let's drop any row that has a missing observation by using \n",
    "the default behaviour of the `dropna` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = titanic.dropna() # Drop any row that has at least one missing value\n",
    "print(cleaned.info())\n",
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a344447",
   "metadata": {},
   "source": [
    "This would only keep 183 values, which isn't a lot. We could also choose to drop only the rows that consist of nothing but missing values (there are no such rows in the `titanic` `DataFrame`), but here you can see how this would be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = titanic.dropna(how=\"all\")\n",
    "cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b75af0",
   "metadata": {},
   "source": [
    "Instead of relying on `info` to compute the number of non missing values we can also use the `isnull` and/or `notnull` methods.\n",
    "`notnull` computes a boolean `DataFrame` where an entry is `True` if and only if that entry is considered to be non missing in the original `DataFrame`. We can then use `sum` the compute the sum of each column. This gives the number of non missing values per column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_df = titanic.notnull()\n",
    "print(not_null_df.tail(3))\n",
    "print(\"Number of non null values in each column:\")\n",
    "print(not_null_df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4d0df",
   "metadata": {},
   "source": [
    "An even easier alternative is to simply use `count` on the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3606a9",
   "metadata": {},
   "source": [
    "The `Cabin` column has too many missing values, so probably isn't useful. For the `Age` column, we can *impute* the missing values, e.g. with the average age of all passengers. (We will see later what this means exactly). Let's do this using `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b356dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First compute the average age\n",
    "avg_age = titanic['Age'].mean()\n",
    "print(f\"(Rounded) Average age of passengers: {round(avg_age)}\")\n",
    "titanic = titanic.fillna(value={'Age' : avg_age})\n",
    "print(\"We should now confirm that the 'Age' column no longer has missing values\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e5ee4",
   "metadata": {},
   "source": [
    "## Creating New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb17e2b",
   "metadata": {},
   "source": [
    "We use a dataset containing $NO_2$ measurements in the the stations of Paris, Antwerp and London.\n",
    "\n",
    "Let's read the data and check whether it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/air_quality_no2.csv\"\n",
    "air_quality = pd.read_csv(URL)\n",
    "print(air_quality.info())\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453be401",
   "metadata": {},
   "source": [
    "We see that \n",
    "- the dates are stored as strings (object)\n",
    "- `datetime` is added as a column and we have a `RangeIndex`.\n",
    "\n",
    "We would like to\n",
    "- parse the dates, so that they are available as `datetime` objects\n",
    "- index the `DataFrame` rows by this date.\n",
    "\n",
    "This can be achieved by specifying the index column and by indicating that dates must be parsed on `read_csv`. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367332d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.read_csv(URL, index_col=0, parse_dates=True)\n",
    "print(air_quality.info())\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9e5401",
   "metadata": {},
   "source": [
    "We can clearly see the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d74337",
   "metadata": {},
   "source": [
    "### Creating a New Column Derived from (an) Existing Column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51741e",
   "metadata": {},
   "source": [
    "Assume we would like to express the concentration of the station in London in mg/m^3\n",
    "\n",
    "*(If we assume temperature of 25 degrees Celsius and pressure of 1013 hPa, the conversion factor is 1.882)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"london_mg_per_cubic\"] = air_quality[\"station_london\"] * 1.882\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844a838",
   "metadata": {},
   "source": [
    "To create a new column, use the `[]` brackets with the new column name at the left side of the assignment.  The computation is done **element wise**, hence there is no need for an explict loop!\n",
    "\n",
    "We can also use multiple columns to derive a new column.\n",
    "\n",
    "Let's check the ratio of the values in Paris versus Antwerp and save the result in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a38417",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality[\"ratio_paris_antwerp\"] = air_quality[\"station_paris\"] / air_quality[\"station_antwerp\"]\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24c220",
   "metadata": {},
   "source": [
    "We can also perform more general mappings on columns, either using a function or a dictionary.\n",
    "\n",
    "Let's work with the Titanic data once more.  Let's say we want to numerically encode the `Sex` column, this can be done as follows. First let's check the unique values in the `Sex` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'male' : 0, 'female' : 1}\n",
    "titanic['Sex'] = titanic['Sex'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f427f9",
   "metadata": {},
   "source": [
    "Let's check whether it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a51ac",
   "metadata": {},
   "source": [
    "Let's add a new feature (i.e. a new column). When `Age` is less than 12 we will call this passenger a `child`, \n",
    "between 12 and 18 a `teen` and over 18 will be `adult`s.  First, we define a Python function implementing \n",
    "this mapping, and then we apply it to the `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_category(age):\n",
    "    if age < 12:\n",
    "        return \"child\"\n",
    "    if age < 18:\n",
    "        return \"teen\"\n",
    "    return \"adult\"\n",
    "\n",
    "titanic['AgeCategory'] = titanic['Age'].map(age_to_category)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83ed19",
   "metadata": {},
   "source": [
    "Here, we only scratched the surface of what is possible with pandas (and indeed, whole books have been written about pandas). In general the pandas getting started guide, the user guide and the API reference are very good resources to find additional information. You can find \n",
    "all of these [here](https://pandas.pydata.org/pandas-docs/stable/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
